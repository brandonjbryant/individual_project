{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">What's Making Red Wine \"Good\"?</font>\n",
    "\n",
    "This notebook aims to classify the quality of red wine using various parameters or features. This will be a classification problem and will try to use various classification models to find best accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert about the data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python and Visualization Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz  \n",
    "\n",
    "#Wrangling/ Exploration\n",
    "import explore\n",
    "import wrangle \n",
    "from wrangle import get_wine_data, split_wine_data \n",
    "\n",
    "#Math\n",
    "from scipy import stats\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "#Warnings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">What's Making Red Wine \"Good\"?</font>\n",
    "\n",
    "## <font color =\"darkgreen\">Executive Summary</font>\n",
    "* __The Problem__\n",
    "    - What is driving the quality in red wine?\n",
    "\n",
    "* __The Goal__\n",
    "    - Identify the drivers for quality rankings in red wine.\n",
    "    - Document my process/ workflow used to accomplish the project goals.\n",
    "    - Demonstrate my process and summarize my findings.\n",
    "\n",
    "* __The Process/ Pipeline__\n",
    "    1. Acquire the Data\n",
    "    2. Prepare\n",
    "    3. Explore\n",
    "    4. Model\n",
    "    5. Create Recommendations Based On Findings\n",
    "\n",
    "\n",
    "## <font color =\"blue\">The Findings</font>\n",
    "* Alcohol was the most significant feature in \n",
    "\n",
    "* We were unable to detect any linear correlation to logerror utilizing this methodology.\n",
    "\n",
    "* Clustering was not the best method to accomplish our goal of predicting logerror  \n",
    "\n",
    "\n",
    "## <font color=\"purple\">Project Planning</font>\n",
    "* The trello board I used to map out my project planning can be found <a href=\"https://trello.com/b/NJcVVZvd/individual-project-board\">[here]</a>.\n",
    "\n",
    "   * `Data Acquisition`: Data is collected from the UCI database with the appropriate function to grab the red wine data from file path and read as a dataframe  \n",
    "   * `Data Prep`: Column data types are appropriate for the data they contain\n",
    "   * `Data Prep`: Missing values are investigated and handled\n",
    "   * `Exploration`: The interaction between independent variables and the target variable is explored using visualization and statistical testing\n",
    "   * `Modeling`: Different classification models are created and their performance is compared. \n",
    "   \n",
    "## <font color=\"red\">Hypotheses:</font>\n",
    "  * Is there a correlation between alcohol and red wine qquality ranking?\n",
    "  * Is there a correlation between sulfates and red wine quality ranking?\n",
    "  * Is there a corrlation between citric acid and red wine quality ranking?\n",
    "\n",
    "#### <a href=\"https://github.com/david-and-brandon-the-sa-se-bros/zillow-clustering-project\">[Data Dictionary can be found here]</a>\n",
    "\n",
    "\n",
    "\n",
    "## <font color=\"green\">Acquisition</font>\n",
    "Data was obtained from the UCI database which can be found <a href\"https://archive.ics.uci.edu/ml/datasets/wine+quality\">here</a> acquired using this fucntion housed in my `wrangle.py` file:\n",
    "\n",
    ">def get_wine_data():\n",
    " \n",
    "   >   df = pd.read_csv('winequality-red.csv')\n",
    "   \n",
    "   >  return df\n",
    "\n",
    "\n",
    "## <font color=\"blue\">Preparation</font>\n",
    "* This data set contained very few nulls or missing vallues, the few that remained were identified and handled using functions housed in my `wrangle.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire the data\n",
    "df = wrangle.get_wine_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'My original dataframe is coming in with {df.shape[0]} rows and {df.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe now has zero nulls to address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 quality scores\n",
    "#Insert percentages here \n",
    "df.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='quality',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 is most populated quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.hist(rwidth=0.9)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Univariate Takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing each feature with quality feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(data=df, x=\"quality\", y=\"fixed acidity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(x = 'quality', y = 'volatile acidity', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(x = 'quality', y = 'citric acid', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(x = 'quality', y = 'residual sugar', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(x = 'quality', y = 'chlorides', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(x = 'quality', y = 'free sulfur dioxide', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(x = 'quality', y = 'free sulfur dioxide', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(x = 'quality', y = 'density', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(x = 'quality', y = 'free sulfur dioxide', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(x = 'quality', y = 'pH', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(x = 'quality', y = 'sulphates', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.lineplot(x = 'quality', y = 'alcohol', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY\n",
    "\n",
    "#### With the increase of the quality score, the composition of chlorides and volatile acidity decreases.\n",
    "\n",
    "#### With the increase for quality score, the compostion of alcohol, sulphates and citric acid increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrangle import split_wine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = split_wine_data(df, stratify_by='quality')\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation heatmap view\n",
    "train.corr() \n",
    "f, ax = plt.subplots(figsize = (10,10))\n",
    "sns.heatmap(train.corr(), annot = True, linewidths=.5, fmt = \".2f\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = train['quality'], y = train['alcohol'],palette='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train.groupby('quality')['alcohol'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue=\"quality\", palette=\"rocket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Takeaways\n",
    "\n",
    "- Quality has a positive correation between alcohol\n",
    "- Quality has a weak negative correlation to volitile_acidicity\n",
    "- Quality has almost no relationship with residual_sugar, free sulfur dioxide, and pH.Should drop these columns.\n",
    "- Alcohol has a weak correlation to pH\n",
    "- Volitile acidicity has a strong negative correlation to citric acid\n",
    "- Density has positive correlation fixed acidicity\n",
    "- Citric acid has positive correlation between fixed acidicity\n",
    "- Citric acid has a negative relationship between volitile acidicity and pH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bivariate Takeaways \n",
    "cat_vars =[\"type\",\"quality\"]\n",
    "quant_vars =[\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(corr)\n",
    "corr_wine_quality = pd.DataFrame(corr.quality)\n",
    "corr_wine_quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here i set a quality threshold to visualize the distribution of \"good\" quality wines and \"bad\" quality wines\n",
    "#If the wine was ranked above a six i placed it in the good category\n",
    "df['quality'] = [1 if i > 6 else 0 for i in df['quality']]\n",
    "sns.countplot(x=df['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.quality.value_counts()\n",
    "sns.barplot(['Bad','Good'],x.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns I don't need\n",
    "df=df.drop(['residual sugar','free sulfur dioxide','pH'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color =\"brown\">Modeling</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find median or mode\n",
    "train.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish new column that contains the mode\n",
    "train[\"most_frequent\"] = 5\n",
    "\n",
    "# Calcuate the baseline accuracy\n",
    "baseline_accuracy = (train.quality == train.most_frequent).mean()\n",
    "print(f'My baseline prediction is survived = 0')\n",
    "print(f'My baseline accuracy is: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I learned a variety of new methods in regards to modeling that I implemented in this project I will explain in the comments what each new function is designated for  for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function gives for each value the same value intervals means between 0-1\n",
    "def normalization(X):\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X)\n",
    "    X_t = (X - mean)/std\n",
    "    return X_t\n",
    "\n",
    "#Train and Test splitting of data     \n",
    "def train_test(X_t, y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_t, y, test_size = 0.3, random_state = 42)\n",
    "    print(\"Train:\",len(x_train), \" - Test:\", len(x_test))\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "#This function finds the optimal hyperparameters of a model which results in the most 'accurate' predictions.\n",
    "def grid_search(name_clf, clf, x_train, x_test, y_train, y_test):\n",
    "    if name_clf == 'Logistic_Regression':\n",
    "        # Logistic Regression \n",
    "        log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "        grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\n",
    "        grid_log_reg.fit(x_train, y_train)\n",
    "        # We automatically get the logistic regression with the best parameters.\n",
    "        log_reg = grid_log_reg.best_estimator_\n",
    "        print(\"Best Parameters for Logistic Regression: \", grid_log_reg.best_estimator_)\n",
    "        print(\"Best Score for Logistic Regression: \", grid_log_reg.best_score_)\n",
    "        print(\"------------------------------------------\")\n",
    "        return log_reg\n",
    "\n",
    "    \n",
    "    elif name_clf == 'Decision_Tree':\n",
    "        # DecisionTree Classifier\n",
    "        tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,30,1)), \n",
    "                  \"min_samples_leaf\": list(range(5,20,1))}\n",
    "        grid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\n",
    "        grid_tree.fit(x_train, y_train)\n",
    "        # tree best estimator\n",
    "        tree_clf = grid_tree.best_estimator_\n",
    "        print(\"Best Parameters for Decision Tree: \", grid_tree.best_estimator_)\n",
    "        print(\"Best Score for Decision Tree: \", grid_tree.best_score_)\n",
    "        print(\"------------------------------------------\")\n",
    "        \n",
    "        #FEATURE IMPORTANCE FOR DECISION TREE\n",
    "        importnce = tree_clf.feature_importances_\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.title(\"Feature Importances of Decision Tree\")\n",
    "        plt.barh(X_t.columns, importnce, align=\"center\")\n",
    "        \n",
    "        return tree_clf\n",
    "    \n",
    "    elif name_clf == 'Random_Forest':\n",
    "        forest_params = {\"bootstrap\":[True, False], \"max_depth\": list(range(2,10,1)), \n",
    "                  \"min_samples_leaf\": list(range(5,20,1))}\n",
    "        grid_forest = GridSearchCV(RandomForestClassifier(), forest_params)\n",
    "        grid_forest.fit(x_train, y_train)\n",
    "        # forest best estimator\n",
    "        forest_clf = grid_forest.best_estimator_\n",
    "        print(\"Best Parameters for Random Forest: \", grid_forest.best_estimator_)\n",
    "        print(\"Best Score for Random Forest: \", grid_forest.best_score_)\n",
    "        print(\"------------------------------------------\")\n",
    "        \n",
    "        #FEATURE IMPORTANCE FOR DECISION TREE\n",
    "        importnce = forest_clf.feature_importances_\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.title(\"Feature Importances of Random Forest\")\n",
    "        plt.barh(X_t.columns, importnce, align=\"center\")\n",
    "        \n",
    "        return forest_clf\n",
    "    \n",
    "def plot_learning_curve(estimator,title, X, y, ylim=None, cv=None, n_jobs=None,\n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, \n",
    "                                                            n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "#Create Applying ClassificTION function\n",
    "def apply_classification(name_clf, clf, x_train, x_test, y_train, y_test):\n",
    "    #Find the best parameters and get the classification with the best parameters as return valu of grid search\n",
    "    grid_clf = grid_search(name_clf, clf, x_train, x_test, y_train, y_test)\n",
    "    \n",
    "    #Plotting the learning curve\n",
    "    # score curves, each time with 30% data randomly selected as a validation set.\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "    plot_learning_curve(grid_clf, name_clf, x_train, y_train, \n",
    "                    ylim=(0.1, 1.01), cv=cv, n_jobs=4)\n",
    "    \n",
    "    #Apply cross validation to estimate the skills of models with 10 split with using best parameters\n",
    "    scores = cross_val_score(grid_clf, x_train, y_train, cv=10)\n",
    "    print(\"Mean Accuracy of Cross Validation: %\", round(scores.mean()*100,2))\n",
    "    print(\"Std of Accuracy of Cross Validation: %\", round(scores.std()*100))\n",
    "    print(\"------------------------------------------\")\n",
    "    \n",
    "    #Predict the test data as selected classifier\n",
    "    clf_prediction = grid_clf.predict(x_test)\n",
    "    clf1_accuracy = sum(y_test == clf_prediction)/len(y_test)\n",
    "    print(\"Accuracy of\",name_clf,\":\",clf1_accuracy*100)\n",
    "    \n",
    "    #print confusion matrix and accuracy score before best parameters\n",
    "    clf1_conf_matrix = confusion_matrix(y_test, clf_prediction)\n",
    "    print(\"Confusion matrix of\",name_clf,\":\\n\", clf1_conf_matrix)\n",
    "    print(\"==========================================\")\n",
    "    return grid_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting my Xand Y\n",
    "X = df.drop(['quality'], axis = 1)\n",
    "#y = pd.DataFrame(data['value'])\n",
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Normalization\n",
    "X_t = normalization(X)\n",
    "print(\"X_t:\", X_t.shape)\n",
    "\n",
    "#Train and Test splitting of data \n",
    "x_train, x_test, y_train, y_test = train_test(X_t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "apply_classification('Logistic_Regression', lr, x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "dt_clf = apply_classification('Decision_Tree', clf, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "apply_classification('Random_Forest', rf, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Takeaways\n",
    "# Random Forest best model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Conclusion\n",
    "* For this individual project, I aimed to analyze which psychochemical are more related with higher quality wine.\n",
    "* Although I ran out of time and was unable to see how my model performs on unseen data, I am confident that the Random Forest model would be sufficient in correctly in predicting on test data.\n",
    "\n",
    "I was able to utilize new methods in order to explore my data as well as model it. if I had more time, I would evaluate my best models performance on unseen data, as well as enhance my exploratory phase. This project would also benefit from access to more features in the data such as grapes, price, etc. that i DID NOT HAVE ACCESS TO USIING THIS PARTICULAR DATA SET.\n",
    "\n",
    "Based on my data exploration I found that :\n",
    "** Alcohol is the most important feature to decide quality of the wine. If the alcohol percentage is high enough, it means that quality of the wine should be better\n",
    "\n",
    "** Sulphates is another selecting criteria for good wines, with high percentage sulphates wine quality is increasing\n",
    "\n",
    "** Citric Acid is another selecting criteria, it should be higher to decide more better wine\n",
    "\n",
    "Should be lower;\n",
    "\n",
    "** Volatile Acidity should be less in the good wine\n",
    "\n",
    "** Sulfur dioxide is another effect to decreasing wine quality and also it causes head ache therefore if there is less sulfur dioxide in wine, it should be selected\n",
    "\n",
    "** Chlorides value has very less effect to quality of the wine but again it is obvious more value of it causes bad quality of the wine\n",
    "\n",
    "Additionally, for marketing point of view, if a customer wants to buy a wine just looking with some psychochemical values can decide what s/he needs to buy. Of course, brand and price feature was evaluated on this research, therefore, it is not a good analysis for saying “it is good wine”. However, it can give some idea for the people who do not have more knowledge about wine for selecting the good wine maybe for just dinner or gift for friends!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
